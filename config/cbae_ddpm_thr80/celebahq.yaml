dataset:
  name: celebahq
  transforms_1: (0.5)
  transforms_2: (0.5)
  img_size: 256
  batch_size: 16
  test_batch_size: 100
  num_channels: 3
model:
  pretrained: google/ddpm-celebahq-256
  type: cbae_ddpm
  latent_shape: [512, 8, 8]
  latent_noise_dim: 512
  input_latent_dim: 10
  has_concepts: True
  concepts: 
      concept_bins: [2, 2, 2, 2, 2, 2, 2, 2, 10]
      concept_names: ["attractive", "lipstick", "mouth-closed", "smiling", "cheekbones", "makeup", "gender", "eyebrows", "unknown"]
      # just dummy mostly, not being used (need to check in basic.py)
      concept_latent: [10, 10, 10, 10, 10, 10, 10, 10, 10]
      emb_size: 16
      concept_output: [2, 2, 2, 2, 2, 2, 2, 2, 10]
      types: ["bin", "bin", "bin", "bin", "bin", "bin", "bin", "bin", "cat"]

train_config:
  epochs: 50
  recon_lr: 0.0002
  conc_lr: 0.0002
  betas: (.5, .99)
  save_model: True
  use_cuda: True
  log_interval: 100
  steps_per_epoch: 1000
  # actually probability threshold but naming according to color mnist training
  margin_thresh: 0.8
  plot_loss: True
evaluation:
  generation: True
  save_images: True
  save_concept_image: True
  save_results: True

