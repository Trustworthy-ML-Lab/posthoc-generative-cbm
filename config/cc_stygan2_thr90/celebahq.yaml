dataset:
  name: celebahq
  transforms_1: (0.5)
  transforms_2: (0.5)
  img_size: 256
  batch_size: 32
  test_batch_size: 100
  num_channels: 3
model:
  pretrained: models/checkpoints/stylegan2-celebahq-256x256.pkl
  type: cc_stygan2
  latent_noise_dim: 512
  input_latent_dim: 10
  has_concepts: True
  # the mapping network outputs (batch_size, 14, 512) sized latents, where 512-vector is repeated 14 times
  num_ws: 14
  concepts: 
      concept_bins: [2, 2, 2, 2, 2, 2, 2, 2]
      concept_names: ["attractive", "lipstick", "mouth-closed", "smiling", "cheekbones", "makeup", "gender", "eyebrows"]
      # just dummy mostly, not being used (need to check in basic.py)
      concept_latent: [10, 10, 10, 10, 10, 10, 10, 10]
      emb_size: 16
      concept_output: [2, 2, 2, 2, 2, 2, 2, 2]
      types: ["bin", "bin", "bin", "bin", "bin", "bin", "bin", "bin"]


train_config:
  epochs: 50
  conc_lr: 0.0002
  betas: (.5, .99)
  save_model: True
  use_cuda: True
  log_interval: 100
  steps_per_epoch: 1000
  pl_prob_thresh: 0.9
  plot_loss: True
evaluation:
  generation: True
  save_images: True
  save_concept_image: True
  save_results: True
